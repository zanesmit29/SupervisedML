{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c87232c",
   "metadata": {},
   "source": [
    "### LangChain for LLM Application development"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4b893c",
   "metadata": {},
   "source": [
    "### Chains in LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85cbf41",
   "metadata": {},
   "source": [
    "The Chain combines the LLM model together with a prompt and with this building block, you can put a bunch of these building blocks together to carry out a sequence on your text or on your other data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45f7dd8",
   "metadata": {},
   "source": [
    "#### LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1941a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install pandas\n",
    "import pandas as pd\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "llm_model = \"llama3:8b\"\n",
    "\n",
    "llm = ChatOllama(temperature=0.0, model=llm_model) #Adjusting the temperature can make the descriptions more 'fun'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "13abe506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Queen Size Sheet Set</td>\n",
       "      <td>I ordered a king size set. My only criticism w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Waterproof Phone Pouch</td>\n",
       "      <td>I loved the waterproof sac, although the openi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Luxury Air Mattress</td>\n",
       "      <td>This mattress had a small hole in the top of i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pillows Insert</td>\n",
       "      <td>This is the best throw pillow fillers on Amazo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Milk Frother Handheld\\n</td>\n",
       "      <td>I loved this product. But they only seem to l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>L'Or Espresso Café \\n</td>\n",
       "      <td>Je trouve le goût médiocre. La mousse ne tient...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hervidor de Agua Eléctrico</td>\n",
       "      <td>Está lu bonita calienta muy rápido, es muy fun...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Product  \\\n",
       "0        Queen Size Sheet Set   \n",
       "1      Waterproof Phone Pouch   \n",
       "2         Luxury Air Mattress   \n",
       "3              Pillows Insert   \n",
       "4     Milk Frother Handheld\\n   \n",
       "5       L'Or Espresso Café \\n   \n",
       "6  Hervidor de Agua Eléctrico   \n",
       "\n",
       "                                              Review  \n",
       "0  I ordered a king size set. My only criticism w...  \n",
       "1  I loved the waterproof sac, although the openi...  \n",
       "2  This mattress had a small hole in the top of i...  \n",
       "3  This is the best throw pillow fillers on Amazo...  \n",
       "4   I loved this product. But they only seem to l...  \n",
       "5  Je trouve le goût médiocre. La mousse ne tient...  \n",
       "6  Está lu bonita calienta muy rápido, es muy fun...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3502085b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zanes\\AppData\\Local\\Temp\\ipykernel_72500\\3537221364.py:6: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain = LLMChain(llm=llm, prompt=prompt)\n"
     ]
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"What is the best name to describe \\\n",
    "        a company that make {product}\"\n",
    ")\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "419ecf8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zanes\\AppData\\Local\\Temp\\ipykernel_72500\\550859008.py:2: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  chain.run(product)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Here are some suggestions for a company name that makes queen-size sheet sets:\\n\\n1. **Regal Bedding Co.**: This name plays off the idea of a queen-sized bed and implies a sense of luxury and quality.\\n2. **Queenly Sheets**: Simple and straightforward, this name highlights the product's focus on queen-size sheets.\\n3. **DreamWeave**: This name evokes the idea of cozy, comfortable bedding that helps you dream big.\\n4. **Royal Rest**: This name conveys a sense of relaxation and rejuvenation, perfect for a company that makes high-quality bed linens.\\n5. **SoftSpun**: This name emphasizes the softness and comfort of the sheets, which is a key selling point for many consumers.\\n6. **Bedding Bliss**: This name suggests that the company's products will bring joy and satisfaction to customers' bedrooms.\\n7. **Queenly Comforts**: This name combines the idea of queen-size bedding with the promise of comfort and relaxation.\\n8. **SlumberCraft**: This name emphasizes the craftsmanship and attention to detail that goes into making high-quality bed linens.\\n9. **Dreamcatcher Bedding**: This name has a whimsical, playful tone and suggests that the company's products will help customers catch their dreams.\\n10. **Luxury Linens Co.**: This name emphasizes the quality and luxury of the company's products, which is perfect for a company that makes high-end bed linens.\\n\\nI hope one of these suggestions sparks some inspiration for your company's name!\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product = \"Queen Size Sheet Set\"\n",
    "chain.run(product)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4394f50",
   "metadata": {},
   "source": [
    "#### SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e244facc",
   "metadata": {},
   "source": [
    "**The idea of sequential chains are to combine multiple chains were the output of the one chain is the input of the next chain**.  \n",
    "\n",
    "SimpleSequentialChain: Single Input/Output  \n",
    "SequentialChain: Multiple Input/Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bacc0883",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c2082656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt template 1\n",
    "first_prompt = ChatPromptTemplate.from_template(\n",
    "    \"What is the best name to describe \\\n",
    "    a company that makes {product}?\"\n",
    ")\n",
    "\n",
    "# Chain 1\n",
    "chain_one = LLMChain(llm=llm, prompt=first_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "72006044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt template 2\n",
    "second_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Write a 20 words description for the following \\\n",
    "    company:{company_name}\"\n",
    ")\n",
    "# chain 2\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bbcf94bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3mHere are some suggestions for a company name that specializes in queen-size sheet sets:\n",
      "\n",
      "1. **Regal Bedding Co.**: This name plays off the idea of a queen-sized bed and implies a sense of luxury and quality.\n",
      "2. **Queenly Sheets**: Simple and straightforward, this name highlights the product focus on queen-size sheets.\n",
      "3. **DreamWeave**: This name evokes a sense of comfort and relaxation, suggesting that your sheet sets will help customers have sweet dreams.\n",
      "4. **SoftTouch Bedding**: This name emphasizes the softness and comfort of your sheet sets, which is likely to be a key selling point for customers.\n",
      "5. **Royal Rest**: This name positions your company as a provider of high-quality bedding that helps customers get a good night's rest, fit for royalty.\n",
      "6. **SlumberCraft Co.**: This name suggests a focus on craftsmanship and attention to detail in the production of your sheet sets.\n",
      "7. **Queenly Quilts & Sheets**: If you also offer quilts or other bed textiles, this name could work well as it includes both products in the company name.\n",
      "8. **Bedding Bliss**: This name conveys a sense of happiness and satisfaction that customers will experience when using your queen-size sheet sets.\n",
      "\n",
      "Remember to choose a name that reflects your brand values, is easy to remember and pronounce, and resonates with your target audience. Good luck with your business!\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mHere is a 20-word description for Regal Bedding Co.:\n",
      "\n",
      "\"Regal Bedding Co. crafts luxurious queen-size sheet sets, prioritizing quality, comfort, and style for the perfect night's rest.\"\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Here is a 20-word description for Regal Bedding Co.:\\n\\n\"Regal Bedding Co. crafts luxurious queen-size sheet sets, prioritizing quality, comfort, and style for the perfect night\\'s rest.\"'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "overall_simple_chain = SimpleSequentialChain(chains=[chain_one, chain_two], verbose=True)\n",
    "overall_simple_chain.run(product)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde6676a",
   "metadata": {},
   "source": [
    "#### SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0c0f5071",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0a5991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt template 1: translate to english\n",
    "first_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Translate the following review to english:\"\n",
    "    \"\\n\\n{Review}\" #Variable passed in at the start\n",
    ")\n",
    "# chain 1: input= Review and output= English_Review\n",
    "chain_one = LLMChain(llm=llm, prompt=first_prompt, \n",
    "                     output_key=\"English_Review\" #Output\n",
    "                    )\n",
    "\n",
    "# prompt template 2: summarize the review\n",
    "second_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Can you summarize the following review in 1 sentence:\"\n",
    "    \"\\n\\n{English_Review}\" #Output of the previous chain is the input for this chain\n",
    ")\n",
    "# chain 2: input= English_Review and output= summary\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt, \n",
    "                     output_key=\"summary\"\n",
    "                    )\n",
    "\n",
    "# prompt template 3: translate to english\n",
    "third_prompt = ChatPromptTemplate.from_template(\n",
    "    \"What language is the following review:\\n\\n{Review}\"\n",
    ")\n",
    "# chain 3: input= Review and output= language\n",
    "chain_three = LLMChain(llm=llm, prompt=third_prompt,\n",
    "                       output_key=\"language\"\n",
    "                      )\n",
    "\n",
    "# prompt template 4: follow up message\n",
    "fourth_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Write a follow up response to the following \"\n",
    "    \"summary in the specified language:\"\n",
    "    \"\\n\\nSummary: {summary}\\n\\nLanguage: {language}\"\n",
    ")\n",
    "# chain 4: input= summary, language and output= followup_message\n",
    "chain_four = LLMChain(llm=llm, prompt=fourth_prompt,\n",
    "                      output_key=\"followup_message\"\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd33fb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overall_chain: input= Review \n",
    "# and output= English_Review,summary, followup_message\n",
    "overall_chain = SequentialChain(\n",
    "    chains=[chain_one, chain_two, chain_three, chain_four], #All teh chains\n",
    "    input_variables=[\"Review\"], #The human input\n",
    "    output_variables=[\"English_Review\", \"summary\",\"language\",\"followup_message\"], #Change to get the answers to the different outputs\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7d90788c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Review': \"Je trouve le goût médiocre. La mousse ne tient pas, c'est bizarre. J'achète les mêmes dans le commerce et le goût est bien meilleur...\\nVieux lot ou contrefaçon !?\",\n",
       " 'English_Review': 'Here\\'s the translation:\\n\\nI find the taste mediocre. The foam doesn\\'t hold up, it\\'s weird. I buy the same ones in stores and the taste is much better...\\n\\nOld batch or counterfeit!?\\n\\n(Note: \"Vieux lot\" is a French idiomatic expression that roughly translates to \"old batch\" or \"stale stock\", implying that the product may be past its expiration date or not fresh. The reviewer is suggesting that the product might be old or fake.)',\n",
       " 'summary': \"The reviewer finds the taste of this product mediocre and the foam doesn't hold up, suspecting it may be an old or counterfeit batch rather than a genuine one.\",\n",
       " 'language': 'The language of this review is French.',\n",
       " 'followup_message': \"Réponse suivante :\\n\\nJe suis en désaccord avec l'avis du réviseur quant à la qualité de ce produit. Selon moi, le goût est tout à fait acceptable et la mousse tient parfaitement bien. Il est possible que le réviseur ait reçu une batch vieillie ou contrefaite, car je suis convaincu que si c'était un produit authentique, il aurait été plus satisfait de sa qualité.\\n\\nTraduction : Follow-up response :\\n\\nI disagree with the reviewer's opinion on the quality of this product. In my opinion, the taste is quite acceptable and the foam holds up perfectly well. It's possible that the reviewer received an old or counterfeit batch, because I'm convinced that if it were a genuine product, they would have been more satisfied with its quality.\"}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = df.Review[5]\n",
    "overall_chain(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27140f0",
   "metadata": {},
   "source": [
    "#### RouterChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fcde3f",
   "metadata": {},
   "source": [
    "This is used to *Route* an input to a chain based on what that input is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117dd003",
   "metadata": {},
   "source": [
    "**If you have multiple sub-chains that specialize each in a particular type of input, then you can use a RouterChain that first decides which sub-chain to pass it two and then passes it to that chain.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bd329fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define different prompt templates for answering different subjects\n",
    "physics_template = \"\"\"You are a very smart physics professor. \\\n",
    "You are great at answering questions about physics in a concise\\\n",
    "and easy to understand manner. \\\n",
    "When you don't know the answer to a question you admit\\\n",
    "that you don't know.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "math_template = \"\"\"You are a very good mathematician. \\\n",
    "You are great at answering math questions. \\\n",
    "You are so good because you are able to break down \\\n",
    "hard problems into their component parts, \n",
    "answer the component parts, and then put them together\\\n",
    "to answer the broader question.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "history_template = \"\"\"You are a very good historian. \\\n",
    "You have an excellent knowledge of and understanding of people,\\\n",
    "events and contexts from a range of historical periods. \\\n",
    "You have the ability to think, reflect, debate, discuss and \\\n",
    "evaluate the past. You have a respect for historical evidence\\\n",
    "and the ability to make use of it to support your explanations \\\n",
    "and judgements.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "computerscience_template = \"\"\" You are a successful computer scientist.\\\n",
    "You have a passion for creativity, collaboration,\\\n",
    "forward-thinking, confidence, strong problem-solving capabilities,\\\n",
    "understanding of theories and algorithms, and excellent communication \\\n",
    "skills. You are great at answering coding questions. \\\n",
    "You are so good because you know how to solve a problem by \\\n",
    "describing the solution in imperative steps \\\n",
    "that a machine can easily interpret and you know how to \\\n",
    "choose a solution that has a good balance between \\\n",
    "time complexity and space complexity. \n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b9edda69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The router chain decides when to use what sub-chain based on the prompt information below. Give a name and description\n",
    "prompt_infos = [\n",
    "    {\n",
    "        \"name\": \"physics\", \n",
    "        \"description\": \"Good for answering questions about physics\", \n",
    "        \"prompt_template\": physics_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"math\", \n",
    "        \"description\": \"Good for answering math questions\", \n",
    "        \"prompt_template\": math_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"History\", \n",
    "        \"description\": \"Good for answering history questions\", \n",
    "        \"prompt_template\": history_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"computer science\", \n",
    "        \"description\": \"Good for answering computer science questions\", \n",
    "        \"prompt_template\": computerscience_template\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8008761f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.router import MultiPromptChain #Chain that is used when routing between different templates\n",
    "#LLMRouterChain uses the LLM itself to route between the different chains\n",
    "#RouterOutputParser parses the output into a dictionary that can be used downstream to determine which chain to use and the input to that chain\n",
    "from langchain.chains.router.llm_router import LLMRouterChain, RouterOutputParser\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "13fe9cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we create the destination chains. These are the chains that will be called by the router\n",
    "destination_chains = {}\n",
    "for p_info in prompt_infos:\n",
    "    name = p_info[\"name\"]\n",
    "    prompt_template = p_info[\"prompt_template\"]\n",
    "    prompt = ChatPromptTemplate.from_template(template=prompt_template)\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "    destination_chains[name] = chain  \n",
    "    \n",
    "destinations = [f\"{p['name']}: {p['description']}\" for p in prompt_infos]\n",
    "destinations_str = \"\\n\".join(destinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c22b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In addition to the destination chain, we also need a default chain\n",
    "#This chain is called when the router cannot decide which chains to use\n",
    "default_prompt = ChatPromptTemplate.from_template(\"{input}\")\n",
    "default_chain = LLMChain(llm=llm,prompt=default_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33109ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\ '\n",
      "C:\\Users\\zanes\\AppData\\Local\\Temp\\ipykernel_72500\\1293037028.py:2: SyntaxWarning: invalid escape sequence '\\ '\n",
      "  MULTI_PROMPT_ROUTER_TEMPLATE = \"\"\"Given a raw text input to a \\\n"
     ]
    }
   ],
   "source": [
    "#Now we define the template that is used by the LLM to route between the different chains\n",
    "#This has instructions of the tasks to be done and also teh specific formatting \n",
    "MULTI_PROMPT_ROUTER_TEMPLATE = \"\"\"Given a raw text input to a \\\n",
    "language model select the model prompt best suited for the input. \\\n",
    "You will be given the names of the available prompts and a \\\n",
    "description of what the prompt is best suited for. \\\n",
    "You may also revise the original input if you think that revising\\\n",
    "it will ultimately lead to a better response from the language model.\n",
    "\n",
    "<< FORMATTING >>\n",
    "Return a markdown code snippet with a JSON object formatted to look like:\n",
    "```json\n",
    "{{{{\n",
    "    \"destination\": string \\ \"DEFAULT\" or name of the prompt to use in {destinations}\n",
    "    \"next_inputs\": string \\ a potentially modified version of the original input\n",
    "}}}}\n",
    "```\n",
    "\n",
    "REMEMBER: The value of “destination” MUST match one of \\\n",
    "the candidate prompts listed below.\\\n",
    "If “destination” does not fit any of the specified prompts, set it to “DEFAULT.”\n",
    "REMEMBER: \"next_inputs\" can just be the original input \\\n",
    "if you don't think any modifications are needed.\n",
    "\n",
    "<< CANDIDATE PROMPTS >>\n",
    "{destinations}\n",
    "\n",
    "<< INPUT >>\n",
    "{{input}}\n",
    "\n",
    "<< OUTPUT (remember to include the ```json)>>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "99a95064",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Destinations referring to the different type of prompt infos given such as maths, computer science etc.\n",
    "#The template is flexible and you can add in more destinations if need be\n",
    "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(\n",
    "    destinations=destinations_str\n",
    ")\n",
    "\n",
    "router_prompt = PromptTemplate(\n",
    "    template=router_template,\n",
    "    input_variables=[\"input\"],\n",
    "    output_parser=RouterOutputParser(), #Helps the LLM decide between which sub-chains to route into\n",
    ")\n",
    "\n",
    "router_chain = LLMRouterChain.from_llm(llm, router_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e206a369",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zanes\\AppData\\Local\\Temp\\ipykernel_72500\\1481339893.py:1: LangChainDeprecationWarning: Please see migration guide here for recommended implementation: https://python.langchain.com/docs/versions/migrating_chains/multi_prompt_chain/\n",
      "  chain = MultiPromptChain(router_chain=router_chain,\n"
     ]
    }
   ],
   "source": [
    "chain = MultiPromptChain(router_chain=router_chain,\n",
    "                         destination_chains=destination_chains,\n",
    "                         default_chain=default_chain, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "38a49aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "physics: {'input': 'What is black body radiation in the context of thermodynamics?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Blackbody radiation! A fundamental concept in thermodynamics, and one that has far-reaching implications for our understanding of heat transfer and energy exchange.\\n\\nIn the context of thermodynamics, a blackbody is an idealized object that absorbs all incident electromagnetic radiation (light) without reflecting or transmitting any of it. In other words, it's a perfect absorber of light. This means that when you shine light on a blackbody, it will absorb all the energy and convert it into heat.\\n\\nNow, when we talk about blackbody radiation, we're referring to the thermal radiation emitted by this idealized object. Since it absorbs all incident radiation, a blackbody will also emit radiation in response to its temperature. This is known as thermal radiation or blackbody radiation.\\n\\nThe key characteristic of blackbody radiation is that it's a perfect radiator – it emits energy at every possible wavelength (or frequency) across the electromagnetic spectrum, depending on its temperature. The hotter the blackbody, the more energetic and intense the radiation will be.\\n\\nIn practical terms, this means that when you heat an object to a certain temperature, it will start emitting thermal radiation in the form of light. For example, when you hold a hot cup of coffee, you can see the steam rising from the surface – that's blackbody radiation!\\n\\nThe mathematical description of blackbody radiation is given by Planck's law, which relates the energy density of the radiation to its frequency and temperature. This fundamental concept has far-reaching implications for fields like astrophysics, materials science, and even medical imaging.\\n\\nSo, there you have it! Blackbody radiation in a nutshell – or rather, a perfectly absorbing and emitting thermal radiator\""
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"What is black body radiation?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "eae91281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "computer science: {'input': 'What is Machine Learning? (in the context of AI and data analysis)'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I'm excited to dive into this topic!\\n\\nMachine learning (ML) is a subfield of artificial intelligence (AI) that enables computers to learn from data without being explicitly programmed. In other words, ML allows systems to improve their performance on a task over time by automatically adjusting their behavior based on the data they receive.\\n\\nHere's how it works:\\n\\n1. **Data Collection**: You gather a dataset related to the problem you want to solve. This can be images, text, audio, or any other type of data.\\n2. **Model Training**: You train a machine learning model using this dataset. The model is essentially a set of algorithms that analyze the data and learn patterns, relationships, and correlations within it.\\n3. **Model Evaluation**: You evaluate the performance of your trained model on a separate test dataset to ensure it generalizes well and doesn't overfit (i.e., performs poorly on new, unseen data).\\n4. **Deployment**: Once you're satisfied with the model's performance, you deploy it in a production environment where it can make predictions or take actions based on new, incoming data.\\n\\nMachine learning is all about developing algorithms that enable computers to:\\n\\n* **Classify** objects into categories (e.g., spam vs. non-spam emails)\\n* **Predict** continuous values (e.g., stock prices or weather forecasts)\\n* **Generate** novel outputs (e.g., text summaries or image synthesis)\\n\\nSome popular machine learning techniques include:\\n\\n1. **Supervised Learning**: The model learns from labeled data to make predictions.\\n2. **Unsupervised Learning**: The model discovers patterns and relationships within the data without labels.\\n3. **Reinforcement Learning**: The model learns by interacting with an environment and receiving rewards or penalties.\\n\\nWhen choosing a machine learning approach, you should consider factors like:\\n\\n* **Time Complexity**: How long does it take to train and deploy the model?\\n* **Space Complexity**: How much memory and storage do you need for the model?\\n* **Accuracy**: How well does the model perform on your specific problem?\\n\\nAs a computer scientist, I can assure you that machine learning is an incredibly powerful tool for solving complex problems in AI and data analysis. With the right approach, you can unlock insights, make predictions, and drive business decisions like never before!\\n\\nNow, if you have any coding questions or need help with implementing a specific ML algorithm, feel free to ask!\""
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"What is Machine Learning?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4866c59a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
