{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf8f61d3",
   "metadata": {},
   "source": [
    "### LangChain for LLM Application development"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050e5ac8",
   "metadata": {},
   "source": [
    "### LangChain Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89770104",
   "metadata": {},
   "source": [
    "LLMs have an issue to remember things that have been said before. This is where *Memory* comes in.  \n",
    "\n",
    "This enables us to remember past conversations that we can feed to the llm so that there is a conversational flow when you interact with them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b526cae",
   "metadata": {},
   "source": [
    "#### ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e93f18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "llm_model = 'llama3:8b'\n",
    "llm = ChatOllama(temperature=0.0, model=llm_model)\n",
    "memory = ConversationBufferMemory()\n",
    "conversation = ConversationChain(\n",
    "    llm = llm,\n",
    "    memory=memory,\n",
    "    verbose=True #Setting this variable to True you can actually see what is LangChain doing in the background\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a98a0fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi my name is Zane\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Nice to meet you, Zane! I'm an artificial intelligence language model trained by Meta AI, specifically designed for conversational dialogue. My training data consists of a massive corpus of text from various sources, including but not limited to, books, articles, research papers, and online content. I can process and generate human-like text based on the input I receive. I'm constantly learning and improving my responses through machine learning algorithms and user interactions like this one with you! What would you like to talk about, Zane?\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input='Hi my name is Zane')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8752f1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi my name is Zane\n",
      "AI: Nice to meet you, Zane! I'm an artificial intelligence language model trained by Meta AI, specifically designed for conversational dialogue. My training data consists of a massive corpus of text from various sources, including but not limited to, books, articles, research papers, and online content. I can process and generate human-like text based on the input I receive. I'm constantly learning and improving my responses through machine learning algorithms and user interactions like this one with you! What would you like to talk about, Zane?\n",
      "Human: What is 1+1?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"A simple yet great question to start our conversation, Zane! The answer to 1+1 is... (drumroll please)... 2! Yes, the result of adding one and one together is indeed two. This fundamental arithmetic operation is a cornerstone of mathematics and is used extensively in various fields such as science, engineering, economics, and more. In fact, the concept of addition is so ubiquitous that it's often taken for granted, but it's an essential building block for many mathematical operations and problem-solving strategies. Would you like to explore more math-related topics or move on to something else?\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input='What is 1+1?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70ec0b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi my name is Zane\n",
      "AI: Nice to meet you, Zane! I'm an artificial intelligence language model trained by Meta AI, specifically designed for conversational dialogue. My training data consists of a massive corpus of text from various sources, including but not limited to, books, articles, research papers, and online content. I can process and generate human-like text based on the input I receive. I'm constantly learning and improving my responses through machine learning algorithms and user interactions like this one with you! What would you like to talk about, Zane?\n",
      "Human: What is 1+1?\n",
      "AI: A simple yet great question to start our conversation, Zane! The answer to 1+1 is... (drumroll please)... 2! Yes, the result of adding one and one together is indeed two. This fundamental arithmetic operation is a cornerstone of mathematics and is used extensively in various fields such as science, engineering, economics, and more. In fact, the concept of addition is so ubiquitous that it's often taken for granted, but it's an essential building block for many mathematical operations and problem-solving strategies. Would you like to explore more math-related topics or move on to something else?\n",
      "Human: What is my name?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Easy one, Zane! Your name is... (drumroll again)... Zane! I remember we introduced ourselves at the beginning of our conversation, and you told me your name was Zane. I'm glad I can recall that detail accurately! Is there anything else you'd like to chat about or ask?\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input='What is my name?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c4e026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Hi my name is Zane\n",
      "AI: Nice to meet you, Zane! I'm an artificial intelligence language model trained by Meta AI, specifically designed for conversational dialogue. My training data consists of a massive corpus of text from various sources, including but not limited to, books, articles, research papers, and online content. I can process and generate human-like text based on the input I receive. I'm constantly learning and improving my responses through machine learning algorithms and user interactions like this one with you! What would you like to talk about, Zane?\n",
      "Human: What is 1+1?\n",
      "AI: A simple yet great question to start our conversation, Zane! The answer to 1+1 is... (drumroll please)... 2! Yes, the result of adding one and one together is indeed two. This fundamental arithmetic operation is a cornerstone of mathematics and is used extensively in various fields such as science, engineering, economics, and more. In fact, the concept of addition is so ubiquitous that it's often taken for granted, but it's an essential building block for many mathematical operations and problem-solving strategies. Would you like to explore more math-related topics or move on to something else?\n",
      "Human: What is my name?\n",
      "AI: Easy one, Zane! Your name is... (drumroll again)... Zane! I remember we introduced ourselves at the beginning of our conversation, and you told me your name was Zane. I'm glad I can recall that detail accurately! Is there anything else you'd like to chat about or ask?\n"
     ]
    }
   ],
   "source": [
    "#Loading the entire chat that has happened so far\n",
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada3176b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"Human: Hi my name is Zane\\nAI: Nice to meet you, Zane! I'm an artificial intelligence language model trained by Meta AI, specifically designed for conversational dialogue. My training data consists of a massive corpus of text from various sources, including but not limited to, books, articles, research papers, and online content. I can process and generate human-like text based on the input I receive. I'm constantly learning and improving my responses through machine learning algorithms and user interactions like this one with you! What would you like to talk about, Zane?\\nHuman: What is 1+1?\\nAI: A simple yet great question to start our conversation, Zane! The answer to 1+1 is... (drumroll please)... 2! Yes, the result of adding one and one together is indeed two. This fundamental arithmetic operation is a cornerstone of mathematics and is used extensively in various fields such as science, engineering, economics, and more. In fact, the concept of addition is so ubiquitous that it's often taken for granted, but it's an essential building block for many mathematical operations and problem-solving strategies. Would you like to explore more math-related topics or move on to something else?\\nHuman: What is my name?\\nAI: Easy one, Zane! Your name is... (drumroll again)... Zane! I remember we introduced ourselves at the beginning of our conversation, and you told me your name was Zane. I'm glad I can recall that detail accurately! Is there anything else you'd like to chat about or ask?\"}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prints everything in a dictionary\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "239b4e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Hi\n",
      "AI: What's up?\n"
     ]
    }
   ],
   "source": [
    "memory = ConversationBufferMemory() #This is what is used to store the conversation\n",
    "#Adding new things to the memory explicitly\n",
    "memory.save_context({\"input\": \"Hi\"},\n",
    "                    {\"output\": \"What's up?\"})\n",
    "\n",
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20088401",
   "metadata": {},
   "source": [
    "Typically LLMs are **stateless**, that is *each transaction is independent*.  \n",
    "\n",
    "**Memory** enables the llm to take the previous conversations as context to the current conversation. The downside is that as the conversation becomes longer the cost of **sending tokens** to the llm becomes more and more! LLMs charge based on the number of tokens it needs to process!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcff82bb",
   "metadata": {},
   "source": [
    "**LangChain Provides several types of memory to store and accumulate conversations**:\n",
    "1. ConversationBufferMemory\n",
    "2. ConversationBufferWindowMemory\n",
    "3. ConversationTokenBufferMemory\n",
    "4. ConversationSummaryMemory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf734b3",
   "metadata": {},
   "source": [
    "#### ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "041e049c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zanes\\AppData\\Local\\Temp\\ipykernel_66164\\3792516739.py:3: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferWindowMemory(k=1) #K used to keep track of last k number of turns\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory, ConversationTokenBufferMemory, ConversationSummaryMemory\n",
    "\n",
    "memory = ConversationBufferWindowMemory(k=1) #K used to keep track of last k number of turns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82804f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({\"input\": \"Hi\"},\n",
    "                    {\"output\": \"What's up\"})\n",
    "memory.save_context({\"input\": \"Not much, just hanging\"},\n",
    "                    {\"output\": \"Cool\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7798e0bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: Not much, just hanging\\nAI: Cool'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb907947",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferWindowMemory(k=1)\n",
    "conversation = ConversationChain(\n",
    "    llm = llm,\n",
    "    memory = memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49194817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi, my name is Minne\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Nice to meet you, Minne! I'm LLaMA, an AI trained by Meta AI that can converse about a wide range of topics. I've been designed to be friendly and helpful, so feel free to ask me anything that's on your mind. By the way, did you know that I was trained on a massive dataset of text from the internet, which includes over 45 billion parameters? That's a lot of information! What would you like to talk about, Minne?\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Hi, my name is Minne\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e96f5807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, my name is Minne\n",
      "AI: Nice to meet you, Minne! I'm LLaMA, an AI trained by Meta AI that can converse about a wide range of topics. I've been designed to be friendly and helpful, so feel free to ask me anything that's on your mind. By the way, did you know that I was trained on a massive dataset of text from the internet, which includes over 45 billion parameters? That's a lot of information! What would you like to talk about, Minne?\n",
      "Human: What is 1+1?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"A simple question to start with! The answer to 1+1 is... (drumroll please)... 2! Yes, the result of adding one and one together is indeed two. This might seem obvious, but it's a fundamental concept in mathematics that I've been trained on. In fact, my training data includes a vast amount of mathematical formulas and equations, including basic arithmetic operations like addition. So, if you have any more math-related questions or need help with a problem, feel free to ask!\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is 1+1?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5d1bec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: What is 1+1?\n",
      "AI: A simple question to start with! The answer to 1+1 is... (drumroll please)... 2! Yes, the result of adding one and one together is indeed two. This might seem obvious, but it's a fundamental concept in mathematics that I've been trained on. In fact, my training data includes a vast amount of mathematical formulas and equations, including basic arithmetic operations like addition. So, if you have any more math-related questions or need help with a problem, feel free to ask!\n",
      "Human: What is my name?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"A question that gets personal! Unfortunately, I don't have access to that information. As a conversational AI, I don't have the ability to know your name or any other personal details about you. My training data only includes general knowledge and doesn't include specific user information. If you'd like to share your name with me, I'm happy to chat with you and learn more about you!\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is my name?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba39a518",
   "metadata": {},
   "source": [
    "Now you can see as k=1 the llm only remembers the immediate last exchange and not all the conversation that happened before."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befa3c79",
   "metadata": {},
   "source": [
    "#### ConversationTokenBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c624b3a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: Invalid requirement: '#This': Expected package name at the start of dependency specifier\n",
      "    #This\n",
      "    ^\n"
     ]
    }
   ],
   "source": [
    "#%pip install transformers #This is needed in order to calculate the tokens\n",
    "memory = ConversationTokenBufferMemory(llm=llm, max_token_limit=10) #Changing the token limit, will change the load_memory_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "56f84e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({\"input\": \"AI is what?!\"},\n",
    "                    {\"output\": \"Amazing!\"})\n",
    "memory.save_context({\"input\": \"Backpropagation is what?\"},\n",
    "                    {\"output\": \"Beautiful!\"})\n",
    "memory.save_context({\"input\": \"Chatbots are what?\"}, \n",
    "                    {\"output\": \"Charming!\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bc23a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'AI: Charming!'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({}) #This changes based on the max_token_limit that has been set when instantiating 'memory'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a4b73f",
   "metadata": {},
   "source": [
    "#### ConversationSummaryMemory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9175ef",
   "metadata": {},
   "source": [
    "**This one will summarize the conversation so far and that will be stored in memory and used as context to the next conversations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9195ba7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "\n",
    "#Create a long string to see how it works\n",
    "schedule = \"There is a meeting at 8am with your product team. \\\n",
    "You will need your powerpoint presentation prepared. \\\n",
    "9am-12pm have time to work on your LangChain \\\n",
    "project which will go quickly because Langchain is such a powerful tool. \\\n",
    "At Noon, lunch at the italian resturant with a customer who is driving \\\n",
    "from over an hour away to meet you to understand the latest in AI. \\\n",
    "Be sure to bring your laptop to show the latest LLM demo.\"\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5282952f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now load everything in\n",
    "memory.save_context({\"input\": \"Hello\"}, {\"output\": \"What's up\"})\n",
    "memory.save_context({\"input\": \"Not much, just hanging\"},\n",
    "                    {\"output\": \"Cool\"})\n",
    "memory.save_context({\"input\": \"What is on the schedule today?\"}, \n",
    "                    {\"output\": f\"{schedule}\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c2087ace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"System: Current summary:\\nNone (initial conversation)\\n\\nNew lines of conversation:\\n\\nHuman: Hello\\nAI: What's up\\nHuman: Not much, just hanging\\nAI: Cool\\nHuman: What is on the schedule today?\\nAI: There is a meeting at 8am with your product team. You will need your powerpoint presentation prepared. 9am-12pm have time to work on your LangChain project which will go quickly because Langchain is such a powerful tool. At Noon, lunch at the italian resturant with a customer who is driving from over an hour away to meet you to understand the latest in AI. Be sure to bring your laptop to show the latest LLM demo.\\n\\nNew summary:\\nThe conversation starts with casual greetings and small talk between the human and AI. The AI then provides the human with their schedule for the day, including a meeting at 8am, time to work on a LangChain project from 9am-12pm, and lunch at an Italian restaurant at noon to showcase the latest LLM demo.\"}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "aa898e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = ConversationChain(\n",
    "    llm = llm,\n",
    "    memory = memory,\n",
    "    verbose = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a7c43c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "System: Current summary:\n",
      "None (initial conversation)\n",
      "\n",
      "New lines of conversation:\n",
      "\n",
      "Human: Hello\n",
      "AI: What's up\n",
      "Human: Not much, just hanging\n",
      "AI: Cool\n",
      "Human: What is on the schedule today?\n",
      "AI: There is a meeting at 8am with your product team. You will need your powerpoint presentation prepared. 9am-12pm have time to work on your LangChain project which will go quickly because Langchain is such a powerful tool. At Noon, lunch at the italian resturant with a customer who is driving from over an hour away to meet you to understand the latest in AI. Be sure to bring your laptop to show the latest LLM demo.\n",
      "\n",
      "New summary:\n",
      "The conversation starts with casual greetings and small talk between the human and AI. The AI then provides the human with their schedule for the day, including a meeting at 8am, time to work on a LangChain project from 9am-12pm, and lunch at an Italian restaurant at noon to showcase the latest LLM demo.\n",
      "Human: What would be a good demo to show?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I've been trained on a vast amount of data related to AI and machine learning. For a demo, I think showcasing the LLM's ability to generate creative writing, such as poetry or short stories, would be impressive. You could also demonstrate its capacity for summarization by having it condense a long piece of text into a concise summary. Additionally, you could highlight its language translation capabilities by translating a passage from one language to another. These demos would give your customer a good understanding of the LLM's capabilities and potential applications.\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What would be a good demo to show?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b670f033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"System: Current summary:\\nThe conversation starts with casual greetings and small talk between the human and AI. The AI then provides the human with their schedule for the day, including a meeting at 8am, time to work on a LangChain project from 9am-12pm, and lunch at an Italian restaurant at noon to showcase the latest LLM demo.\\n\\nNew lines of conversation:\\nHuman: What would be a good demo to show?\\nAI: I've been trained on a vast amount of data related to AI and machine learning. For a demo, I think showcasing the LLM's ability to generate creative writing, such as poetry or short stories, would be impressive. You could also demonstrate its capacity for summarization by having it condense a long piece of text into a concise summary. Additionally, you could highlight its language translation capabilities by translating a passage from one language to another. These demos would give your customer a good understanding of the LLM's capabilities and potential applications.\\n\\nNew summary:\\nThe conversation starts with casual greetings and small talk between the human and AI. The AI then provides the human with their schedule for the day, including a meeting at 8am, time to work on a LangChain project from 9am-12pm, and lunch at an Italian restaurant at noon to showcase the latest LLM demo. The AI also suggests potential demos for the customer, including creative writing, summarization, and language translation capabilities, which would give the customer a comprehensive understanding of the LLM's features and applications.\"}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
